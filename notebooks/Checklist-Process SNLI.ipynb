{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.expect import Expect\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import numpy as np\n",
    "processor = spacy.load('en_core_web_sm')\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../trained_model_snli/'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.12.5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('text-classification', model=model,\n",
    "                        tokenizer=tokenizer, device=0)\n",
    "pipe_all = pipeline('text-classification', model=model,\n",
    "                        tokenizer=tokenizer, device=0, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/eric/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The sisters are hugging goodbye while holding ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>Two woman are holding packages.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The men are fighting outside a deli.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids at a ballgame wash their hands.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Two women are embracing while holding to go pa...   \n",
       "1  Two women are embracing while holding to go pa...   \n",
       "2  Two women are embracing while holding to go pa...   \n",
       "3  Two young children in blue jerseys, one with t...   \n",
       "4  Two young children in blue jerseys, one with t...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  The sisters are hugging goodbye while holding ...      1  \n",
       "1                    Two woman are holding packages.      0  \n",
       "2               The men are fighting outside a deli.      2  \n",
       "3     Two kids in numbered jerseys wash their hands.      0  \n",
       "4           Two kids at a ballgame wash their hands.      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dev_dataset = load_dataset('snli', split='validation')\n",
    "dev_df = dev_dataset.to_pandas()\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_qs = [(row.premise, row.hypothesis) for _, row in dev_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess all the questions with spacy. This may take sometime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 999.33it/s]\n",
      "10000it [00:06, 1541.28it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_p = list(tqdm(processor.pipe(dev_df.premise, batch_size=64)))\n",
    "processed_h = list(tqdm(processor.pipe(dev_df.hypothesis, batch_size=64)))\n",
    "parsed_qs_spacy = [(p, q) for (p, q) in zip(processed_p, processed_h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Two women are embracing while holding to go packages.,\n",
       " The sisters are hugging goodbye while holding to go packages after just eating lunch.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_qs_spacy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Model: QQP, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we'll use Quora Question Pair as an example, with [a finetuned BERT model hosted by Textattack](https://huggingface.co/textattack/bert-base-uncased-QQP).\n",
    "**Please note that this is not the model reported in the paper -- we finetuned that model locally.** \n",
    "Here, we instead use a model that is available online (loaded through [Huggingface Pipeline](https://huggingface.co/transformers/main_classes/pipelines.html)), so that you can easily follow the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-Down approach: the CheckList matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capabilities x Test Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutorial #3, we talked about specific test types.  \n",
    "In order to guide test ideation, it's useful to think of CheckList as a matrix of Capabilities x Test Types.  \n",
    "*Capabilities* refers to general-purpose linguistic capabilities, which manifest in one way or another in almost any NLP application.   \n",
    "We suggest that anyone CheckListing a model go through *at least* the following capabilities, trying to create MFTs, INVs, and DIRs for each if possible.\n",
    "1. **Vocabulary + POS:** important words or groups of words (by part-of-speech) for the task\n",
    "2. **Taxonomy**: synonyms, antonyms, word categories, etc\n",
    "3. **Robustness**: to typos, irrelevant additions, contractions, etc\n",
    "4. **Named Entity Recognition (NER)**: person names, locations, numbers, etc\n",
    "5. **Fairness**\n",
    "6. **Temporal understanding**: understanding order of events and how they impact the task\n",
    "7. **Negation**\n",
    "8. **Coreference** \n",
    "9. **Semantic Role Labeling (SRL)**: understanding roles such as agent, object, passive/active, etc\n",
    "10. **Logic**: symmetry, consistency, conjunctions, disjunctions, etc\n",
    "\n",
    "Notice that we are framing this as very top-down approach: you start with a list of capabilities and try to think of what kinds of tests can be created, based on the three test types. We'll talk about how to incorporate some bottom-up thinking later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't try to create tests for **all** of these capabilities (but we do have notebooks with tests for all of them in the repo), just one as an example. \n",
    "Anyway, let's create a test suite (used to save and aggregate tests):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the NER capability.  \n",
    "How do named entities impact duplicate question detection? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Two women are embracing while holding to go packages.',\n",
       " 'The sisters are hugging goodbye while holding to go packages after just eating lunch.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(dev_df.iloc[i].label)\n",
    "parsed_qs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFT\n",
    "It seems that the model should be able to label as contradiction when name is changed.   \n",
    "Let's write an MFT where we have two people that have the same last name, but different first names.  \n",
    "Instead of running the test now, we'll add it to the suite and run all tests later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/lib/python3.7/site-packages/checklist/text_generation.py:171: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  to_pred = torch.tensor(to_pred, device=self.device).to(torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Robin Perry is staying at home', 'Julia Perry is staying at home')\n",
      "('Grace Ross is not at Disneyland', 'Rebecca Ross is not at Disneyland')\n"
     ]
    }
   ],
   "source": [
    "t = editor.template((\n",
    "    '{first_name} {last_name} is {mask} at {mask}',\n",
    "    '{first_name2} {last_name} is {mask} at {mask}',\n",
    "    ),\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "test = MFT(**t, labels=2, name='same adjectives, different people', capability = 'NER',\n",
    "           description='Different first name, same adjective and last name')\n",
    "suite.add(test, overwrite=True)\n",
    "print(t.data[0])\n",
    "print(t.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Jason likes to do chores in advance', 'Jason does not like to do chores in advance')\n",
      "('Alice likes to do dishes in public', 'Alice does not like to do dishes in public')\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(('{first_name} likes to do {mask} in {mask}', '{first_name} does not like to do {mask} in {mask}'),\n",
    "                remove_duplicates=True, \n",
    "                nsamples=300)\n",
    "test = MFT(**t, labels=2, name='Negation contradiction', description='', capability='Negation')\n",
    "suite.add(test, overwrite=True)\n",
    "print(t.data[0])\n",
    "print(t.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('same adjectives, different people',\n",
       "              <checklist.test_types.MFT at 0x7f2471dc8e50>),\n",
       "             ('Negation contradiction',\n",
       "              <checklist.test_types.MFT at 0x7f2479b38a10>)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite.tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INV\n",
    "If you have two questions with the same named entity, changing the entity on both should not change whether the questions are duplicates or not.  \n",
    "Let's write an INV for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with pairs of questions, we have to write a wrapper to make sure the same name is changed on both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two women having drinks with women and smoking cigarettes at the bar.',\n",
       " 'Two men having drinks with men and smoking cigarettes at the bar.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def change_gender(text):\n",
    "    # not perfect... there is some ambiguity in that her -> his or him depending on context\n",
    "    female_words = ['woman', 'women', 'she', 'her', 'hers', 'girl', 'girls', 'sister',  'sisters',  'daughter', 'daughters']\n",
    "    male_words   = ['man',   'men',   'he',  'him', 'his',  'boy',  'boys',  'brother', 'brothers', 'son',      'sons']\n",
    "    \n",
    "    # completely swapping gender doesn't work yet. \n",
    "    ret = []\n",
    "    for i, word in enumerate(male_words):\n",
    "        swapped = re.sub(r'\\b%s\\b' % word, female_words[i], text, flags=re.I)\n",
    "        if swapped != text:\n",
    "            ret += [swapped]\n",
    "    for i, word in enumerate(female_words):\n",
    "        swapped = re.sub(r'\\b%s\\b' % word, male_words[i], text, flags=re.I)\n",
    "        if swapped != text:\n",
    "            ret += [swapped]\n",
    "    return ret\n",
    "\n",
    "change_gender(\"Two women having drinks with men and smoking cigarettes at the bar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def change_gender_on_both(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = change_gender(q1.text)\n",
    "    c2 = change_gender(q2.text)\n",
    "    # Only include examples where the same name was changed on both questions\n",
    "    return [(q1, q2) for q1, q2 in zip(c1, c2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Three young girls are walking hand in hand in a crowd of people.', 'A group of girls try to make their way through the crowd at a concert.'), ('Three young boys are walking hand in hand in a crowd of people.', 'A group of boys try to make their way through the crowd at a concert.')]\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs_spacy, change_gender_on_both, nsamples=200)\n",
    "test = INV(**t, name='Change gender in both', capability='NER',\n",
    "          description='')\n",
    "# test.run(new_pp)\n",
    "# test.summary(3)\n",
    "suite.add(test, overwrite=True)\n",
    "print(t.data[0])\n",
    "#print(t.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIR\n",
    "Conversely, if an entity is present on a pair the model predicts as a duplicate and we change it to something else on *only one* of the sentences, the prediction should change to non-duplicate.  \n",
    "Let's write this as a DIR test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_gender_on_one(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = change_gender(q1.text)\n",
    "    c2 = change_gender(q2.text)\n",
    "    # there needs to be gendered word in both\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "\n",
    "    ret = []\n",
    "    ret.extend([(q1_changed, str(q2)) for q1_changed in c1])\n",
    "    ret.extend([(str(q1), q2_changed) for q2_changed in c2])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write an expectation function in two steps.  \n",
    "First, we want the prediction to be 0.  \n",
    "Second, we only want to include examples where the original prediction is one. We do this with a slice wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want changes to make the case go towards 2 (contradiction). \n",
    "expect_fn = Expect.eq(2)\n",
    "expect_fn = Expect.slice_orig(expect_fn, lambda orig, *args: orig != 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together into a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Two young girls are playing large stringed instruments behind music stands, with a window in the background.', 'The girls are musicians.')\n",
      "('Two young boys are playing large stringed instruments behind music stands, with a window in the background.', 'The girls are musicians.')\n",
      "('Two young girls are playing large stringed instruments behind music stands, with a window in the background.', 'The boys are musicians.')\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs_spacy, change_gender_on_one, nsamples=200)\n",
    "name = 'Change gender in one of the questions'\n",
    "desc = 'Take non-contradictions. Change gender in one to make contradictions.'\n",
    "test = DIR(**t, expect=expect_fn, name=name, description=desc, capability='NER')\n",
    "suite.add(test)\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the suite, seeing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the prediction, the Huggingface pipeline returns a dict with predicted label and probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.38768288493156433}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ('The woman likes driving', 'The woman likes cars')\n",
    "pipe([[example]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a simple wrapper to make the output compatible with CheckList:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_conf(data):\n",
    "    data = [[d] for d in data]\n",
    "    raw_preds = pipe_all(data)\n",
    "    pp = np.array([[p[0]['score'], p[1]['score'], p[2]['score']] for p in raw_preds])\n",
    "    preds = np.argmax(pp, axis=1)\n",
    "    return preds, pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running same adjectives, different people\n",
      "Predicting 298 examples\n",
      "Running Negation contradiction\n",
      "Predicting 300 examples\n",
      "Running Change gender in both\n",
      "Predicting 428 examples\n",
      "Running Change gender in one of the questions\n",
      "Predicting 706 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(pred_and_conf, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a (text) summary of the results by calling `suite.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      298\n",
      "Fails (rate):    132 (44.3%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.2 0.1 ('Victoria Howard is speaking at BYU', 'Maria Howard is speaking at BYU')\n",
      "----\n",
      "0.4 0.2 0.3 ('Melissa Bell is home at Thanksgiving', 'Marilyn Bell is home at Thanksgiving')\n",
      "----\n",
      "0.6 0.2 0.2 ('Margaret Jackson is away at work', 'Jennifer Jackson is away at work')\n",
      "----\n",
      "\n",
      "\n",
      "Change gender in both\n",
      "Test cases:      200\n",
      "Fails (rate):    24 (12.0%)\n",
      "\n",
      "Example fails:\n",
      "0.3 0.1 0.7 ('A young women, in a black shirt, is holding a bike, while a young boy is holding a skateboard.', 'A young woman is holding a bike while a young man is holding a skateboard.')\n",
      "1.0 0.0 0.0 ('A young women, in a black shirt, is holding a bike, while a young girl is holding a skateboard.', 'A young woman is holding a bike while a young woman is holding a skateboard.')\n",
      "0.9 0.0 0.0 ('A young men, in a black shirt, is holding a bike, while a young boy is holding a skateboard.', 'A young man is holding a bike while a young man is holding a skateboard.')\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 ('2 rows of woman walking towards each other on the sidewalk outside of a store with a boy 50% sign on the golden framed windows.', 'The women are in two rows.')\n",
      "0.0 0.0 1.0 ('2 rows of woman walking towards each other on the sidewalk outside of a store with a girl 50% sign on the golden framed windows.', 'The men are in two rows.')\n",
      "\n",
      "----\n",
      "0.0 1.0 0.0 ('A woman prays while a young girl lights a fire', 'The girl is lighting a fire to roast marshmallows.')\n",
      "0.0 0.0 1.0 ('A man prays while a young girl lights a fire', 'The boy is lighting a fire to roast marshmallows.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change gender in one of the questions\n",
      "Test cases:      200\n",
      "After filtering: 142 (71.0%)\n",
      "Fails (rate):    57 (40.1%)\n",
      "\n",
      "Example fails:\n",
      "0.0 0.5 0.4 ('A man wearing blue jeans and a black shirt is talking to a man wearing white shorts while they are sitting outside in folding chairs on a patio.', 'the woman is white')\n",
      "0.0 1.0 0.0 ('A man wearing blue jeans and a black shirt is talking to a man wearing white shorts while they are sitting outside in folding chairs on a patio.', 'the man is white')\n",
      "0.0 1.0 0.0 ('A woman wearing blue jeans and a black shirt is talking to a woman wearing white shorts while they are sitting outside in folding chairs on a patio.', 'the woman is white')\n",
      "\n",
      "----\n",
      "0.0 1.0 0.0 ('The woman is holding the hand of the little girl in the red dress with the polka-dotted skirt.', \"A child wearing polka dots hold her mom's hand as they walk to school.\")\n",
      "0.0 1.0 0.0 ('The woman is holding the hand of the little boy in the red dress with the polka-dotted skirt.', \"A child wearing polka dots hold her mom's hand as they walk to school.\")\n",
      "0.0 1.0 0.0 ('The woman is holding the hand of the little girl in the red dress with the polka-dotted skirt.', \"A child wearing polka dots hold him mom's hand as they walk to school.\")\n",
      "\n",
      "----\n",
      "1.0 0.0 0.0 ('A girl in a striped black and white sweater holds on to her friend who is bent over wearing a hooded black sweater and torn blue jeans.', 'The girl is wearing jeans.')\n",
      "1.0 0.0 0.0 ('A girl in a striped black and white sweater holds on to him friend who is bent over wearing a hooded black sweater and torn blue jeans.', 'The girl is wearing jeans.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Negation contradiction\n",
      "Test cases:      300\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we're using jupyter, we can use a nifty visualization that has all of the tests we created in a matrix.  \n",
    "You can navigate the matrix and see results for individual tests (*The screenshot below is based on our locally finetuned model, so the numbers may not match with your results.*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce79033a69e242758f7a258d745debd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'same adjectives, dif…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import HTML, Image\n",
    "# with open('visual_table_summary.gif','rb') as f:\n",
    "#     display(Image(data=f.read(), format='png'))\n",
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: testing Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a few additional tests for the Taxonomy capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eric/anaconda3/lib/python3.7/site-packages/pattern/text/en/../../../../multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('grateful', 'thankful'), ('cautious', 'conservative', 'timid'), ('conservative', 'cautious'), ('organised', 'organized', 'direct', 'engineer'), ('stressed', 'stress'), ('mean', 'average', 'hateful'), ('smart', 'wise', 'chic', 'bright'), ('honest', 'good', 'true', 'reliable', 'honorable', 'fair'), ('hateful', 'mean'), ('worried', 'upset'), ('ambitious', 'challenging'), ('dependent', 'qualified'), ('rigid', 'strict', 'stiff', 'fixed'), ('demanding', 'exact'), ('important', 'significant', 'authoritative'), ('organized', 'organised', 'direct'), ('corrupt', 'corrupted'), ('miserable', 'poor', 'pathetic', 'suffering', 'wretched', 'low'), ('enlightened', 'educated', 'clear'), ('tolerant', 'resistant', 'liberal', 'kind'), ('vocal', 'outspoken'), ('thankful', 'grateful'), ('educated', 'enlightened'), ('intimidating', 'daunting'), ('unhappy', 'distressed'), ('thoughtful', 'attentive'), ('committed', 'attached'), ('strict', 'rigid', 'stern'), ('charitable', 'benevolent', 'sympathetic'), ('courageous', 'brave'), ('authentic', 'reliable'), ('authoritarian', 'dictator'), ('evil', 'vicious'), ('needy', 'impoverished'), ('addicted', 'addict'), ('clear', 'open', 'clean', 'light', 'clearly'), ('vain', 'futile'), ('aware', 'mindful'), ('so', 'then'), ('intelligent', 'healthy', 'thinking', 'sound'), ('bad', 'sorry', 'tough', 'risky', 'spoiled', 'defective'), ('fat', 'productive', 'rich', 'fatty'), ('inspired', 'divine'), ('ethical', 'honorable'), ('hungry', 'thirsty'), ('innovative', 'modern', 'advanced'), ('fit', 'set'), ('individual', 'single', 'private', 'person', 'someone'), ('efficient', 'effective'), ('passive', 'peaceful', 'inactive')\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.synonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        tmp.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(', '.join([str(tuple(x)) for x in tmp][:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of those, let's pick a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, we can create a simple MFT, where we expect the model to recognize these synonyms.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    (\n",
    "    'How can I become {moreless} {x[0]}?',\n",
    "    'How can I become {moreless} {x[1]}?',\n",
    "    ),\n",
    "    x=synonyms,\n",
    "    moreless=['more', 'less'],\n",
    "    remove_duplicates=True, \n",
    "    nsamples=200)\n",
    "name = 'How can I become more {synonym}?' \n",
    "desc = 'different (simple) templates where words are replaced with their synonyms'\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with antonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cautious', 'brave'),('conservative', 'progressive', 'liberal'),('smart', 'stupid'),('conspicuous', 'invisible'),('pessimistic', 'optimistic'),('dependent', 'independent'),('impatient', 'patient'),('powerless', 'powerful'),('corrupt', 'straight'),('unhappy', 'happy'),('courageous', 'fearful'),('evil', 'good'),('visible', 'invisible'),('optimistic', 'pessimistic'),('bad', 'good'),('fat', 'lean', 'thin'),('hungry', 'thirsty'),('individual', 'common'),('irresponsible', 'responsible'),('passive', 'active'),('insecure', 'secure'),('uncomfortable', 'comfortable'),('defensive', 'offensive'),('shy', 'confident'),('negative', 'positive'),('invisible', 'visible'),('active', 'passive'),('humble', 'proud'),('hopeful', 'hopeless'),('progressive', 'conservative'),('difficult', 'easy'),('specific', 'general'),('positive', 'negative'),('organic', 'functional'),('rude', 'civil', 'polite'),('emotional', 'intellectual'),('stupid', 'smart', 'intelligent')\n"
     ]
    }
   ],
   "source": [
    "opps = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        opps.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(','.join([str(tuple(x)) for x in opps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cautious', 'brave'],\n",
       " ['conservative', 'progressive', 'liberal'],\n",
       " ['smart', 'stupid'],\n",
       " ['conspicuous', 'invisible'],\n",
       " ['pessimistic', 'optimistic'],\n",
       " ['dependent', 'independent'],\n",
       " ['impatient', 'patient'],\n",
       " ['powerless', 'powerful'],\n",
       " ['corrupt', 'straight'],\n",
       " ['unhappy', 'happy'],\n",
       " ['courageous', 'fearful'],\n",
       " ['evil', 'good'],\n",
       " ['visible', 'invisible'],\n",
       " ['optimistic', 'pessimistic'],\n",
       " ['bad', 'good'],\n",
       " ['fat', 'lean', 'thin'],\n",
       " ['hungry', 'thirsty'],\n",
       " ['individual', 'common'],\n",
       " ['irresponsible', 'responsible'],\n",
       " ['passive', 'active'],\n",
       " ['insecure', 'secure'],\n",
       " ['uncomfortable', 'comfortable'],\n",
       " ['defensive', 'offensive'],\n",
       " ['shy', 'confident'],\n",
       " ['negative', 'positive'],\n",
       " ['invisible', 'visible'],\n",
       " ['active', 'passive'],\n",
       " ['humble', 'proud'],\n",
       " ['hopeful', 'hopeless'],\n",
       " ['progressive', 'conservative'],\n",
       " ['difficult', 'easy'],\n",
       " ['specific', 'general'],\n",
       " ['positive', 'negative'],\n",
       " ['organic', 'functional'],\n",
       " ['rude', 'civil', 'polite'],\n",
       " ['emotional', 'intellectual'],\n",
       " ['stupid', 'smart', 'intelligent']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template([(\n",
    "    'How can I become more {x[0]}?',\n",
    "    'How can I become less {x[1]}?',\n",
    "    ),\n",
    "    (\n",
    "    'How can I become less {x[0]}?',\n",
    "    'How can I become more {x[1]}?',\n",
    "    )],\n",
    "    unroll=True,\n",
    "    x=antonyms,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "name = 'How can I become more X = How can I become less antonym(X)' \n",
    "desc = ''\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be easy to turn the synonym one into an INV as well (we do this in another notebook), but let's end here after we run the suite again and see new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running same adjectives, different people\n",
      "Predicting 298 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2065 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/lib/python3.7/site-packages/transformers/pipelines/base.py:910: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Change name in one of the questions\n",
      "Predicting 3912 examples\n",
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 376 examples\n",
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(pred_and_conf, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      376\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taxonomy\n",
      "\n",
      "How can I become more {synonym}?\n",
      "Test cases:      200\n",
      "Fails (rate):    34 (17.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 ('How can I become more spiritual?', 'How can I become more religious?')\n",
      "----\n",
      "0.0 ('How can I become less vocal?', 'How can I become less outspoken?')\n",
      "----\n",
      "0.0 ('How can I become less vocal?', 'How can I become less outspoken?')\n",
      "----\n",
      "\n",
      "\n",
      "How can I become more X = How can I become less antonym(X)\n",
      "Test cases:      600\n",
      "Fails (rate):    344 (57.3%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become less optimistic?', 'How can I become more pessimistic?')\n",
      "----\n",
      "0.0 ('How can I become more cautious?', 'How can I become less brave?')\n",
      "----\n",
      "0.0 ('How can I become more impatient?', 'How can I become less patient?')\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      298\n",
      "Fails (rate):    74 (24.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 ('Is Harry Cooper Missing?', 'Is Donald Cooper Missing?')\n",
      "----\n",
      "0.7 ('Is Annie Harrison free?', 'Is Amanda Harrison free?')\n",
      "----\n",
      "0.6 ('Is Al Gray alive?', 'Is Samuel Gray alive?')\n",
      "----\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    21 (10.5%)\n",
      "\n",
      "Example fails:\n",
      "1.0 ('Will Indians face any difficulty if Donald Trump becomes the President of USA?', 'How will Donald Trump benefit India?')\n",
      "0.0 ('Will Indians face any difficulty if Michael Brooks becomes the President of USA?', 'How will Michael Brooks benefit India?')\n",
      "0.0 ('Will Indians face any difficulty if Joseph Anderson becomes the President of USA?', 'How will Joseph Anderson benefit India?')\n",
      "\n",
      "----\n",
      "0.9 ('How is Donald Trump viewed in Norway?', 'Is Donald Trump popular in Norway?')\n",
      "0.2 ('How is James Parker viewed in Norway?', 'Is James Parker popular in Norway?')\n",
      "\n",
      "----\n",
      "0.9 ('Was Paul McCartney replaced by a lookalike?', 'Did Paul McCartney die and get replaced?')\n",
      "0.4 ('Was James Parker replaced by a lookalike?', 'Did James Parker die and get replaced?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "After filtering: 118 (59.0%)\n",
      "Fails (rate):    35 (29.7%)\n",
      "\n",
      "Example fails:\n",
      "0.9 ('Should I vote for Donald Trump or Hillary Clinton?', 'Do you support Donald Trump or Hillary Clinton? Why?')\n",
      "0.6 ('Should I vote for Donald Trump or Elizabeth Johnson?', 'Do you support Donald Trump or Hillary Clinton? Why?')\n",
      "0.6 ('Should I vote for Donald Trump or Hillary Clinton?', 'Do you support Donald Trump or Elizabeth Johnson? Why?')\n",
      "\n",
      "----\n",
      "1.0 ('Will Donald Trump end up in some conflict of interest?', 'Will Donald trump end up in conflicts of interest?')\n",
      "1.0 ('Will Donald Trump end up in some conflict of interest?', 'Matthew Davis trump end up in conflicts of interest?')\n",
      "1.0 ('Will Donald Trump end up in some conflict of interest?', 'Joshua Thompson trump end up in conflicts of interest?')\n",
      "\n",
      "----\n",
      "1.0 ('What do you think about the rapist Donald Trump?', 'What do intelligent people think about Donald Trump?')\n",
      "0.7 ('What do you think about the rapist Donald Trump?', 'What do intelligent people think about William Perez?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb58923209341aeab18044275955cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'same adjectives, dif…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
